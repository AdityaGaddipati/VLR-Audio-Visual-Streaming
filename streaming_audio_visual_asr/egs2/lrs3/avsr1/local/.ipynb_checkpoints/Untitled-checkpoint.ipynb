{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib, cv2, os\n",
    "import numpy as np\n",
    "import skvideo\n",
    "import skvideo.io\n",
    "from tqdm import tqdm\n",
    "from align_mouth import landmarks_interpolate, crop_patch, write_video_ffmpeg\n",
    "# from IPython.display import HTML\n",
    "# from base64 import b64encode\n",
    "import argparse\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "def detect_landmark(image, detector, predictor):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    rects = detector(gray, 1)\n",
    "    coords = None\n",
    "    for (_, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        coords = np.zeros((68,2), dtype = np.int32)\n",
    "        for i in range(0, 68):\n",
    "            coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "        return coords\n",
    "    \n",
    "def preprocess_video(input_video_path, output_video_path, face_predictor_path, mean_face_path, ffmpeg_path):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(face_predictor_path)\n",
    "    STD_SIZE = (256, 256)\n",
    "    mean_face_landmarks = np.load(mean_face_path)\n",
    "    stablePntsIDs = [33, 36, 39, 42, 45]\n",
    "    videogen = skvideo.io.vread(input_video_path)\n",
    "    frames = np.array([frame for frame in videogen])\n",
    "    landmarks = []\n",
    "    for frame in frames:\n",
    "        landmark = detect_landmark(frame, detector, predictor)\n",
    "        landmarks.append(landmark)\n",
    "    preprocessed_landmarks = landmarks_interpolate(landmarks)\n",
    "    if(preprocessed_landmarks is None):\n",
    "        # 60% center crop the original video\n",
    "        crop_video(input_video_path, output_video_path)\n",
    "        return False\n",
    "    rois = crop_patch(input_video_path, preprocessed_landmarks, mean_face_landmarks, stablePntsIDs, STD_SIZE, \n",
    "                        window_margin=12, start_idx=48, stop_idx=68, crop_height=96, crop_width=96)\n",
    "    write_video_ffmpeg(rois, output_video_path, ffmpeg_path)\n",
    "    return True\n",
    "\n",
    "def crop_video(input_video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    w_frame, h_frame = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    x, y, w, h = int(w_frame * 0.2), int(h_frame * 0.2), int(w_frame * 0.6), int(h_frame * 0.6)\n",
    "\n",
    "    crop_writer = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, crop_writer, fps, (w, h))\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\">>> {} Cannot read mp4 file: vision features unavailable\".format(input_video_path))\n",
    "        # Final solution - copy original file video\n",
    "        shutil.copyfile(input_video_path, output_video_path)\n",
    "    while success:       \n",
    "        crop_frame = frame[y:y+h, x:x+w]\n",
    "        out.write(crop_frame)\n",
    "        success, frame = cap.read()\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -O /scratch/karthikg/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
    "# !bzip2 -d /scratch/karthikg/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
    "\n",
    "\n",
    "# !wget --content-disposition https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy -O /scratch/karthikg/misc/20words_mean_face.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_path = \"/usr/bin/ffmpeg\"\n",
    "face_predictor_path = \"/scratch/karthikg/misc/shape_predictor_68_face_landmarks.dat\"\n",
    "mean_face_path = \"/scratch/karthikg/misc/20words_mean_face.npy\"\n",
    "\n",
    "#Prepare Mouth ROI Video\n",
    "train_val_path = \"/scratch/karthikg/datasets/lrs3/trainval\"\n",
    "test_path = \"/scratch/karthikg/datasets/lrs3/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 412/412 [00:00<00:00, 16851.00it/s]\n",
      "100%|██████████| 4004/4004 [00:00<00:00, 13357.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm \n",
    "\n",
    "logging.info(f\"Performing Data Preparation for TEST\")\n",
    "for subdir in tqdm.tqdm(os.listdir(test_path)):\n",
    "    root = os.path.join(test_path, subdir)\n",
    "    for f in os.listdir(root):\n",
    "        fname = os.path.splitext(f)\n",
    "        if f.endswith(\".mp4\"):\n",
    "            if fname[0].endswith(\"mouth_roi\"):\n",
    "                continue\n",
    "            elif os.path.exists(os.path.join(root, fname[0] + \"_mouth_roi\" + fname[1])):\n",
    "                continue\n",
    "            else:\n",
    "                input_path = os.path.join(root, f)\n",
    "                output_path = os.path.join(root, fname[0] + \"_mouth_roi\" + fname[1])\n",
    "                if not preprocess_video(input_path, output_path, face_predictor_path, mean_face_path, ffmpeg_path):\n",
    "                    count += 1\n",
    "                file_count += 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "roi_required = []\n",
    "for subdir in tqdm.tqdm(os.listdir(train_val_path)):\n",
    "    root = os.path.join(train_val_path, subdir)\n",
    "    for f in os.listdir(root):\n",
    "        fname = os.path.splitext(f)\n",
    "        if f.endswith(\".mp4\"):\n",
    "            if fname[0].endswith(\"mouth_roi\"):\n",
    "                continue\n",
    "            elif os.path.exists(os.path.join(root, fname[0] + \"_mouth_roi\" + fname[1])):\n",
    "                continue\n",
    "            else:\n",
    "                input_path = os.path.join(root, f)\n",
    "                output_path = os.path.join(root, fname[0] + \"_mouth_roi\" + fname[1])\n",
    "#                 if not preprocess_video(input_path, output_path, face_predictor_path, mean_face_path, ffmpeg_path):\n",
    "                roi_required.append((input_path, output_path)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in roi_required:\n",
    "    output_path\n",
    "    preprocess_video(input_path, output_path, face_predictor_path, mean_face_path, ffmpeg_path):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
